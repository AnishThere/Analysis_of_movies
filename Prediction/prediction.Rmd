---
title: "Prediction"
output: html_document
---

### Loading the required libraries

```{r}
library(ggplot2)
library(dplyr)
library(Hmisc)
library(psych)
library(tidyr)
```

### Reading the dataset

```{r}
movie <- read.csv('../Preprocessing/movie_clean.csv', stringsAsFactors = F)
str(movie)
```

### Multiple Linear Regression - Variable Selection


```{r}
movie_sub <- subset(movie, select = c(3, 4, 5, 8, 9, 13, 15, 22, 27, 28:53, 25, 26))
```

***

Only selecting numeric values for the regression model

***

### Construct the model

```{r}
set.seed(123)
train_size <- 0.8 
train_index <- sample.int(length(movie$imdb_score), length(movie$imdb_score) * train_size)
train_sample <- movie[train_index,]
test_sample <- movie[-train_index,]
```

### Fit the model 

```{r}
fit <- lm(imdb_score ~ num_critic_for_reviews + duration +    director_facebook_likes + actor_1_facebook_likes + gross + cast_total_facebook_likes + facenumber_in_poster + budget + movie_facebook_likes + Action + Adventure + Fantasy +  Thriller + Documentary + Romance + Animation + Comedy + Family + Musical +  Mystery + Western + Drama + History + Sport + Crime + Horror + War + Biography + Music + News + Short, data=train_sample)
summary(fit) 
```

***

Model with all the variables

***

```{r}
fit <- lm(imdb_score ~ num_critic_for_reviews + duration +  director_facebook_likes + actor_1_facebook_likes +  cast_total_facebook_likes + facenumber_in_poster + Action + Thriller + Documentary + Animation + Comedy + Family + Mystery + Drama + Crime + Horror + War + Biography + Music, data=train_sample)
summary(fit) 
```

***

Model with only the significant variables. The median for the residual error is close to 0 and the absolute minimum and maximum values are also close which means that the average residual error is approximately 0. The adjusted R-squared value is 0.29 which means the model can explain only 29% of the variation. 

***

```{r}
plot(fit)
```

***

From the residuals vs fitted graph we can see that there are quite a few outliers at the end and overall the dispersion is uneven. From the Normal Q-Q plot we can see that there is a huge deviation at the start.
 
***

```{r}
train_sample$pred_score <- predict(fit, newdata = subset(train_sample, select=c(imdb_score, num_critic_for_reviews, duration, director_facebook_likes, actor_1_facebook_likes, cast_total_facebook_likes, facenumber_in_poster, movie_facebook_likes, Action ,Adventure, Fantasy,Thriller, Documentary ,Romance ,Animation ,Comedy ,Family ,Musical ,Mystery, Western ,Drama ,History ,Sport ,Crime ,Horror,War ,Biography ,Music, News ,Short)))
test_sample$pred_score <- predict(fit, newdata = subset(test_sample, select=c(imdb_score, num_critic_for_reviews, duration, director_facebook_likes, actor_1_facebook_likes, cast_total_facebook_likes, facenumber_in_poster, movie_facebook_likes, Action ,Adventure, Fantasy,Thriller, Documentary ,Romance ,Animation ,Comedy ,Family ,Musical ,Mystery, Western ,Drama ,History ,Sport ,Crime ,Horror,War ,Biography ,Music, News ,Short)))
```

### Evaluating on train set

```{r}
train_corr <- round(cor(train_sample$pred_score, train_sample$imdb_score), 2)
train_rmse <- round(sqrt(mean((train_sample$pred_score - train_sample$imdb_score)^2)), 2)
train_mae <- round(mean(abs(train_sample$pred_score - train_sample$imdb_score)), 2)
c(train_corr^2, train_rmse, train_mae)
```

***

The predicted and the actual scores are not highly correlated.
RMSE value is high which means the model doesn't fit the data well
MAE is also high which is bad as the predicted imdb score values lie in 0-10 range

***

### Evaluating on test set

```{r}
test_rmse <- round(sqrt(mean((test_sample$pred_score - test_sample$imdb_score)^2)), 2)
test_mae <- round(mean(abs(test_sample$pred_score - test_sample$imdb_score)), 2)
c(test_rmse, test_mae)
```

***

Test set also has high RMSE and MAE values 

***

### Decision Tree

```{r}
library(rpart)
library(rpart.plot)
```

```{r}
movie_sub_dectre <- movie
movie_sub_dectre$imdb_cat <- as.numeric(cut2(movie_sub$imdb_score, g=3))

movie_sub_dectre$imdb_cat <- factor(x=movie_sub_dectre$imdb_cat, levels=sort(unique(movie_sub_dectre$imdb_cat)), labels = c("Low", "Medium", "High"))
```

***

Distributing the scores into 3 different categories Low, Medium and High

***

```{r}
set.seed(123)
train_size <- 0.8 
train_index <- sample.int(length(movie_sub_dectre$imdb_cat), length(movie_sub_dectre$imdb_cat) * train_size)
train_sample <- movie_sub_dectre[train_index,]
test_sample <- movie_sub_dectre[-train_index,]
```

```{r}
fit <- rpart(imdb_cat ~ num_critic_for_reviews + duration + budget + director_facebook_likes + actor_1_facebook_likes + cast_total_facebook_likes + facenumber_in_poster + movie_facebook_likes + Action + Adventure + Fantasy +  Thriller + Documentary + Romance + Animation + Comedy + Family + Musical +  Mystery + Western + Drama + History + Sport + Crime + Horror + War + Biography + Music + News + Short, data=train_sample, method = 'class')
rpart.plot(fit)
```

```{r}
predicted <- predict(fit, test_sample, type = 'class')
table_mat <- table(test_sample$imdb_cat, predicted)
table_mat
```

```{r}
accuracy_Test <- sum(diag(table_mat)) / sum(table_mat)
print(paste('Accuracy for test', accuracy_Test))
```

***

Accuracy of 54% was achieved on the test data using the decision tree classifier

***

## Naive bayees using geners only

```{r}
library(e1071)
```

```{r}
genre_sub <- subset(movie_sub_dectre, select = c(29:55))

index <- sample(1 : nrow(genre_sub), round(0.75 * nrow(genre_sub)))

train_cl <- genre_sub[index, ]
test_cl <- genre_sub[-index, ]

set.seed(120)  

classifier_cl <- naiveBayes(imdb_cat ~ ., data = train_cl)
classifier_cl
```

```{r}
y_pred <- predict(classifier_cl, newdata = test_cl)

cm <- table(test_cl$imdb_cat, y_pred)
cm
print(paste("Accuracy", sum(diag(cm)) / sum(cm)))
```

***

Accuracy of 41% was achieved with Naive bayees classifier

***

### KNN

```{r}
library(caTools)
library(class)
```

```{r}
set.seed(123)
train_size <- 0.8 
train_index <- sample.int(length(movie_sub_dectre$imdb_cat), length(movie_sub_dectre$imdb_cat) * train_size)
train_sample <- movie_sub_dectre[train_index,]
test_sample <- movie_sub_dectre[-train_index,]

train_sample <- na.omit(train_sample)
test_sample <- na.omit(test_sample)

train_cl <- subset(train_sample, select = c(29:54))
test_cl <- subset(test_sample, select = c(29:54))

classifier_knn <- knn(train = train_cl,
                      test = test_cl,
                      cl = train_sample$imdb_cat,
                      k =100)
cm <- table(test_sample$imdb_cat, classifier_knn)
cm
misClassError <- mean(classifier_knn != test_sample$imdb_cat)
print(paste('Accuracy =', 1-misClassError))
```

***

Accuracy of 42% was achieved with KNN classifier

***


## Neural networks

```{r}
library(neuralnet)
```

```{r}
movie_sub_dectre$imdb_num <- factor(x=movie_sub_dectre$imdb_cat, levels=sort(unique(movie_sub_dectre$imdb_cat)), labels = c(1,2,3))
#movie_sub_dectre$imdb_num = as.numeric(movie_sub_dectre$imdb_num)

#movie_idk = select(movie_sub_dectre, -c("imdb_cat"))
movie_idk <- subset(movie_sub_dectre, select=c(4,5,6,9,14,16,26,28, 55))
movie_idk$imdb_num <- factor(x=movie_idk$imdb_cat, levels=sort(unique(movie_idk$imdb_cat)), labels = c(1,2,3))
movie_idk$imdb_num = as.numeric(movie_idk$imdb_num)
movie_idk <- select(movie_idk, -c("imdb_cat"))
```

```{r}
index <- sample(1 : nrow(movie_idk),
                round(0.75 * nrow(movie_idk)))
maxs <- apply(movie_idk, 2, max)
mins <- apply(movie_idk, 2, min)
scaled <- as.data.frame(scale(movie_idk,
                              center = mins,
                              scale = maxs - mins))
aa = movie_idk[index, ]
ab = movie_idk[-index, ]

train_ <- scaled[index, ]
test_ <- scaled[-index, ]

train_$imdb_num = as.numeric(as.factor(aa$imdb_num))
test_$imdb_num = as.numeric(as.factor(ab$imdb_num))
```

```{r}
NN = neuralnet(imdb_num ~ num_critic_for_reviews + duration + director_facebook_likes + actor_1_facebook_likes + cast_total_facebook_likes + facenumber_in_poster + movie_facebook_likes, data=train_, hidden = 2)
plot(NN)
```
![](nn.png)
```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```


